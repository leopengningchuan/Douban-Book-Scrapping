{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2b5461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T01:23:49.220458Z",
     "start_time": "2025-05-06T01:23:48.780965Z"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, requests, math\n",
    "import os, dotenv\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6234d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T01:23:49.223550Z",
     "start_time": "2025-05-06T01:23:49.221543Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the user_id, user_agent and cookie for douban.env\n",
    "dotenv.load_dotenv(\"douban.env\")\n",
    "user_id, user_agent, cookie  = os.getenv(\"user_id\"), os.getenv(\"user_agent\"), os.getenv(\"cookie\")\n",
    "\n",
    "# generate the header\n",
    "header = {'User-Agent': user_agent, 'Cookie': cookie}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a608ba56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T01:23:49.227717Z",
     "start_time": "2025-05-06T01:23:49.224086Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define the function of parse each book in one page\n",
    "def get_books_info_from_page(url, header):\n",
    "    \n",
    "    # create the dataframe for all used columns\n",
    "    page_data = pd.DataFrame(columns = ['Name', 'Pub_info', 'Date', 'Star', 'Tag', 'Comment', 'Website'])\n",
    "    \n",
    "    # get the web data from the url\n",
    "    web_data = requests.get(url, headers = header)\n",
    "    soup = BeautifulSoup(web_data.text, features = \"lxml\")\n",
    "\n",
    "    # parse by each book\n",
    "    for div in soup.select('div.info'):\n",
    "        if div.find('a').contents[0] == '读书主页':\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                # get the feature of each book\n",
    "                book_name = str(div.find('a').contents[0]).replace('  ','').replace('\\n','')\n",
    "                book_pubinfo = str(div.select('div.pub')).split('>')[1].split('<')[0].replace('  ','').replace('\\n','')\n",
    "                book_date = str(div.select('span.date')).split('>')[1].split('<')[0][:10]\n",
    "                book_comment = str(div.find('p')).split('>')[1].split('<')[0].replace('  ','').replace('\\n','')\n",
    "                book_tag = str(div.select('span.tags')).split('>')[1].split('<')[0][4:]\n",
    "                book_star = [i for i in range(1, 6) if div.select(f'span.rating{i}-t')][0]\n",
    "                book_website = re.search(r'href=\"([^\"]+)\"', str(div.select('a')[0])).group(1)\n",
    "                \n",
    "                # combine the features in one row\n",
    "                book_parse = pd.DataFrame({'Name': book_name, 'Pub_info': book_pubinfo, \n",
    "                                           'Date': book_date, 'Star': book_star, \n",
    "                                           'Tag': book_tag, 'Comment': book_comment, \n",
    "                                           'Website': book_website}, \n",
    "                                           index=[0])\n",
    "                \n",
    "                # concat the book info together\n",
    "                page_data = pd.concat([page_data, book_parse], ignore_index = True)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                # print 'error' if wrong\n",
    "                print(book_name, 'parse error')\n",
    "                \n",
    "    return page_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340ab2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T01:24:24.883116Z",
     "start_time": "2025-05-06T01:23:49.228679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total book #: 491\n",
      "Parsing books: 1 ~ 15...\n",
      "Parsing books: 16 ~ 30...\n",
      "Parsing books: 31 ~ 45...\n",
      "Parsing books: 46 ~ 60...\n",
      "Parsing books: 61 ~ 75...\n",
      "Parsing books: 76 ~ 90...\n",
      "Parsing books: 91 ~ 105...\n",
      "Parsing books: 106 ~ 120...\n",
      "Parsing books: 121 ~ 135...\n",
      "Parsing books: 136 ~ 150...\n",
      "Parsing books: 151 ~ 165...\n",
      "Parsing books: 166 ~ 180...\n",
      "Parsing books: 181 ~ 195...\n",
      "Parsing books: 196 ~ 210...\n",
      "Parsing books: 211 ~ 225...\n",
      "Parsing books: 226 ~ 240...\n",
      "Parsing books: 241 ~ 255...\n",
      "Parsing books: 256 ~ 270...\n",
      "Parsing books: 271 ~ 285...\n",
      "Parsing books: 286 ~ 300...\n",
      "Parsing books: 301 ~ 315...\n",
      "Parsing books: 316 ~ 330...\n",
      "Parsing books: 331 ~ 345...\n",
      "Parsing books: 346 ~ 360...\n",
      "Parsing books: 361 ~ 375...\n",
      "Parsing books: 376 ~ 390...\n",
      "Parsing books: 391 ~ 405...\n",
      "Parsing books: 406 ~ 420...\n",
      "Parsing books: 421 ~ 435...\n",
      "Parsing books: 436 ~ 450...\n",
      "Parsing books: 451 ~ 465...\n",
      "Parsing books: 466 ~ 480...\n",
      "Parsing books: 481 ~ 495...\n",
      "Parsing books: 496 ~ 491...\n",
      "Finish parsing all books.\n"
     ]
    }
   ],
   "source": [
    "# create the data for all dataframe\n",
    "data = pd.DataFrame(columns = ['Name', 'Pub_info', 'Date', 'Star', 'Tag', 'Comment', 'Website'])\n",
    "\n",
    "# get the number of books\n",
    "url = f'https://book.douban.com/people/{user_id}/collect?start=0&sort=time&rating=all&filter=all&mode=grid'\n",
    "web_data = requests.get(url, headers = header)\n",
    "soup = BeautifulSoup(web_data.text, features=\"lxml\")\n",
    "\n",
    "web_title = str(soup.title).split('>')[1].split('<')[0].replace('  ','').replace('\\n','')\n",
    "num_books = int(re.findall(r\"\\(\\s*\\+?(-?\\d+)\\s*\\)\", web_title)[0])\n",
    "print('Total book #:', num_books)\n",
    "\n",
    "# parse the book information by page\n",
    "for i in range(0, math.ceil(num_books / 15)+1): # num_books ange(0, math.ceil(num_books / 15)+1)\n",
    "    if i != math.ceil(num_books / 15):\n",
    "        print(f'Parsing books: {i*15+1} ~ {i*15+15}...')\n",
    "    else:\n",
    "        print(f'Parsing books: {i*15+1} ~ {num_books}...')\n",
    "    url = f'https://book.douban.com/people/{user_id}/collect?start={i*15}&sort=time&rating=all&filter=all&mode=grid'\n",
    "    book_info = get_books_info_from_page(url, header)\n",
    "    data = pd.concat([data, book_info], ignore_index = True)\n",
    "    \n",
    "print('Finish parsing all books.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1397879e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T01:24:24.900471Z",
     "start_time": "2025-05-06T01:24:24.885171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Pub_info</th>\n",
       "      <th>Date</th>\n",
       "      <th>Star</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>透明的红萝卜</td>\n",
       "      <td>莫言 / 浙江文艺出版社 / 2020-7 / 49.00元</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>4</td>\n",
       "      <td>汉语文学 现当代文学</td>\n",
       "      <td>《透明的红萝卜》是莫言的成名作，作为他作品中的第一个“特异儿童”（后续中有《生死疲劳》中一出...</td>\n",
       "      <td>https://book.douban.com/subject/35096959/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>爆炸</td>\n",
       "      <td>莫言 / 浙江文艺出版社 / 2020-7 / 46.00元</td>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>4</td>\n",
       "      <td>汉语文学 现当代文学</td>\n",
       "      <td>《爆炸》描写了一个丈夫在得知妻子怀孕后，在特殊年代不得不带着妻子去流产。传统观念和现代思想，...</td>\n",
       "      <td>https://book.douban.com/subject/35096965/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>沉思</td>\n",
       "      <td>[奥地利] 弗朗茨·卡夫卡 / 彤雅立 / 北京燕山出版社 / 2021-1 / 45.00</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>2</td>\n",
       "      <td>外国文学 德语文学</td>\n",
       "      <td>这本书是卡夫卡于29岁发表的第一本书。大部分都是灵光乍现的小短文，看上去似乎有些没头没尾的。...</td>\n",
       "      <td>https://book.douban.com/subject/35218473/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name                                        Pub_info       Date Star  \\\n",
       "488  透明的红萝卜                  莫言 / 浙江文艺出版社 / 2020-7 / 49.00元 2025-04-15    4   \n",
       "489      爆炸                  莫言 / 浙江文艺出版社 / 2020-7 / 46.00元 2025-04-26    4   \n",
       "490      沉思  [奥地利] 弗朗茨·卡夫卡 / 彤雅立 / 北京燕山出版社 / 2021-1 / 45.00 2025-05-06    2   \n",
       "\n",
       "            Tag                                            Comment  \\\n",
       "488  汉语文学 现当代文学  《透明的红萝卜》是莫言的成名作，作为他作品中的第一个“特异儿童”（后续中有《生死疲劳》中一出...   \n",
       "489  汉语文学 现当代文学  《爆炸》描写了一个丈夫在得知妻子怀孕后，在特殊年代不得不带着妻子去流产。传统观念和现代思想，...   \n",
       "490   外国文学 德语文学  这本书是卡夫卡于29岁发表的第一本书。大部分都是灵光乍现的小短文，看上去似乎有些没头没尾的。...   \n",
       "\n",
       "                                       Website  \n",
       "488  https://book.douban.com/subject/35096959/  \n",
       "489  https://book.douban.com/subject/35096965/  \n",
       "490  https://book.douban.com/subject/35218473/  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the final parsed data\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.sort_values('Date').reset_index(drop=True)\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a797ecaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T01:24:25.061696Z",
     "start_time": "2025-05-06T01:24:24.901748Z"
    }
   },
   "outputs": [],
   "source": [
    "# export the data to a excel file\n",
    "data.to_excel(\"book_review_sample_result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da107bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
